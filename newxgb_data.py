import pandas as pd
import numpy as np
import json
from typing import Dict, Any, List
import itertools
from datetime import datetime, timedelta

class DigitalTwinBigDataGenerator:
    """
    ì–¸ë¦¬ì–¼ ë””ì§€í„¸ íŠ¸ìœˆ ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ë¹…ë°ì´í„° ìƒì„±ê¸°
    ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ML í›ˆë ¨ìš© ë°ì´í„°ì…‹ êµ¬ì¶•
    """
    
    def __init__(self):
        # ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„° ë²”ìœ„ ì •ì˜
        self.scenario_parameters = {
            # ì°½ê³  ê·œëª¨ë³„
            "warehouse_sizes": [
                {"area": 50000000, "description": "ì†Œí˜•ì°½ê³  5,000mÂ²"},      # 5ì²œë§Œ cmÂ²
                {"area": 100000000, "description": "ì¤‘í˜•ì°½ê³  10,000mÂ²"},    # 1ì–µ cmÂ²  
                {"area": 150000000, "description": "ëŒ€í˜•ì°½ê³  15,000mÂ²"},    # 1.5ì–µ cmÂ²
                {"area": 300000000, "description": "ì´ˆëŒ€í˜•ì°½ê³  30,000mÂ²"},  # 3ì–µ cmÂ²
            ],
            
            # ì¥ë¹„ êµ¬ì„±ë³„
            "equipment_configs": [
                {
                    "name": "ê¸°ë³¸í˜•",
                    "conveyor": (5, 15),     # 5-15ëŒ€
                    "rtv": (2, 8),          # 2-8ëŒ€
                    "srm": (3, 12),         # 3-12ëŒ€
                    "robot_arm": (0, 2),    # 0-2ëŒ€
                    "automation_level": 2
                },
                {
                    "name": "í‘œì¤€í˜•", 
                    "conveyor": (10, 25),
                    "rtv": (4, 12),
                    "srm": (5, 15),
                    "robot_arm": (1, 3),
                    "automation_level": 3
                },
                {
                    "name": "ê³ ê¸‰í˜•",
                    "conveyor": (15, 35),
                    "rtv": (6, 18),
                    "srm": (8, 20),
                    "robot_arm": (1, 4),
                    "automation_level": 4
                },
                {
                    "name": "ìµœê³ ê¸‰í˜•",
                    "conveyor": (20, 50),
                    "rtv": (10, 25),
                    "srm": (10, 30),
                    "robot_arm": (2, 6),
                    "automation_level": 5
                }
            ],
            
            # ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤ë³„
            "operation_scenarios": [
                {
                    "name": "í‰ì‹œ",
                    "throughput_multiplier": 1.0,
                    "delay_multiplier": 1.0,
                    "error_rate": 0.03
                },
                {
                    "name": "ì„±ìˆ˜ê¸°",
                    "throughput_multiplier": 1.8,
                    "delay_multiplier": 1.4,
                    "error_rate": 0.05
                },
                {
                    "name": "ë¹„ìˆ˜ê¸°",
                    "throughput_multiplier": 0.6,
                    "delay_multiplier": 0.8,
                    "error_rate": 0.02
                },
                {
                    "name": "í”¼í¬íƒ€ì„",
                    "throughput_multiplier": 2.2,
                    "delay_multiplier": 2.0,
                    "error_rate": 0.08
                },
                {
                    "name": "ì•¼ê°„ìš´ì˜",
                    "throughput_multiplier": 0.7,
                    "delay_multiplier": 0.9,
                    "error_rate": 0.04
                }
            ],
            
            # ì¥ë¹„ ìƒíƒœë³„
            "equipment_conditions": [
                {
                    "name": "ìµœì ìƒíƒœ",
                    "efficiency_factor": 1.0,
                    "breakdown_rate": 0.01
                },
                {
                    "name": "ì–‘í˜¸ìƒíƒœ", 
                    "efficiency_factor": 0.9,
                    "breakdown_rate": 0.03
                },
                {
                    "name": "ë³´í†µìƒíƒœ",
                    "efficiency_factor": 0.8,
                    "breakdown_rate": 0.05
                },
                {
                    "name": "ë…¸í›„ìƒíƒœ",
                    "efficiency_factor": 0.7,
                    "breakdown_rate": 0.1
                }
            ]
        }
    
    def generate_simulation_scenarios(self, num_scenarios_per_combination: int = 50) -> List[Dict]:
        """
        ì²´ê³„ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ ì¡°í•© ìƒì„±
        """
        scenarios = []
        scenario_id = 1
        
        # ëª¨ë“  ì¡°í•© ìƒì„±
        for warehouse in self.scenario_parameters["warehouse_sizes"]:
            for equipment in self.scenario_parameters["equipment_configs"]:
                for operation in self.scenario_parameters["operation_scenarios"]:
                    for condition in self.scenario_parameters["equipment_conditions"]:
                        
                        # ê° ì¡°í•©ë‹¹ ì—¬ëŸ¬ ë²ˆ ì‹œë®¬ë ˆì´ì…˜ (ë…¸ì´ì¦ˆ ì¶”ê°€)
                        for variation in range(num_scenarios_per_combination):
                            scenario = self._create_single_scenario(
                                scenario_id, warehouse, equipment, operation, condition, variation
                            )
                            scenarios.append(scenario)
                            scenario_id += 1
        
        print(f"ğŸ“Š ì´ {len(scenarios):,}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ")
        print(f"   â€¢ ì°½ê³  ê·œëª¨: {len(self.scenario_parameters['warehouse_sizes'])}ê°€ì§€")
        print(f"   â€¢ ì¥ë¹„ êµ¬ì„±: {len(self.scenario_parameters['equipment_configs'])}ê°€ì§€") 
        print(f"   â€¢ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤: {len(self.scenario_parameters['operation_scenarios'])}ê°€ì§€")
        print(f"   â€¢ ì¥ë¹„ ìƒíƒœ: {len(self.scenario_parameters['equipment_conditions'])}ê°€ì§€")
        print(f"   â€¢ ë³€ë™ ì¼€ì´ìŠ¤: {num_scenarios_per_combination}ê°œ/ì¡°í•©")
        
        return scenarios
    
    def _create_single_scenario(self, scenario_id: int, warehouse: Dict, equipment: Dict, 
                              operation: Dict, condition: Dict, variation: int) -> Dict:
        """
        ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        """
        # ê¸°ë³¸ ë…¸ì´ì¦ˆ íŒ©í„°
        noise_factor = 1 + np.random.normal(0, 0.1)  # Â±10% ë…¸ì´ì¦ˆ
        
        # ì¥ë¹„ ìˆ˜ëŸ‰ ê²°ì •
        conveyor_count = np.random.randint(equipment["conveyor"][0], equipment["conveyor"][1] + 1)
        rtv_count = np.random.randint(equipment["rtv"][0], equipment["rtv"][1] + 1)
        srm_count = np.random.randint(equipment["srm"][0], equipment["srm"][1] + 1)
        robot_arm_count = np.random.randint(equipment["robot_arm"][0], equipment["robot_arm"][1] + 1)
        rack_count = max(10, int(warehouse["area"] / 5000000))  # ë©´ì  ëŒ€ë¹„ ë™ ìˆ˜
        
        # ì²˜ë¦¬ëŸ‰ ê³„ì‚°
        base_throughput = warehouse["area"] / 20000  # ë©´ì  ê¸°ë°˜ ê¸°ë³¸ ì²˜ë¦¬ëŸ‰
        actual_throughput = (base_throughput * operation["throughput_multiplier"] * 
                           condition["efficiency_factor"] * noise_factor)
        
        # ì‹œê°„ ì§€í‘œ ê³„ì‚°
        base_actual_time = 5 + np.random.normal(0, 2)  # ê¸°ë³¸ 5ì´ˆ Â± 2ì´ˆ
        base_delay_time = base_actual_time * (2 - condition["efficiency_factor"]) * operation["delay_multiplier"]
        base_wait_time = np.random.exponential(10) * (1 + operation["error_rate"])
        base_idle_time = np.random.exponential(2)
        
        # ì¥ë¹„ë³„ íŠ¹ì„± ë°˜ì˜
        equipment_performance = {}
        
        # ì»¨ë² ì´ì–´
        cnv_actual = base_actual_time * np.random.uniform(0.8, 1.2)
        cnv_delay = base_delay_time * np.random.uniform(1.5, 3.0)  # ì»¨ë² ì´ì–´ëŠ” ì§€ì—° ë§ìŒ
        cnv_wait = base_wait_time * np.random.uniform(2.0, 4.0)   # ëŒ€ê¸°ë„ ë§ìŒ
        cnv_idle = base_idle_time * np.random.uniform(0.1, 0.8)
        cnv_inbound = int(actual_throughput * 0.4 * np.random.uniform(0.8, 1.2))  # 40% ë‹´ë‹¹
        cnv_outbound = int(cnv_inbound * np.random.uniform(0.0, 0.3))  # ë‚®ì€ ì™„ë£Œìœ¨
        
        equipment_performance["cnv"] = {
            "Count": str(conveyor_count),
            "AvgActualTime": f"{cnv_actual:.6f}",
            "AvgDelayTime": f"{cnv_delay:.6f}",
            "AvgWaitTime": f"{cnv_wait:.6f}",
            "AvgIdleTime": f"{cnv_idle:.6f}",
            "TotalInbound": str(cnv_inbound),
            "TotalOutbound": str(cnv_outbound)
        }
        
        # RTV (AGV)
        rtv_actual = base_actual_time * np.random.uniform(2.0, 4.0)  # AGVëŠ” ì´ë™ì‹œê°„ í¬í•¨
        rtv_delay = base_delay_time * np.random.uniform(0.5, 2.0)
        rtv_wait = base_wait_time * np.random.uniform(0.1, 1.0)
        rtv_idle = base_idle_time * np.random.uniform(0.5, 2.0)
        rtv_inbound = int(actual_throughput * 0.2 * np.random.uniform(0.8, 1.2))  # 20% ë‹´ë‹¹
        rtv_outbound = int(rtv_inbound * np.random.uniform(0.1, 0.6))  # ì¤‘ê°„ ì™„ë£Œìœ¨
        
        equipment_performance["rtv"] = {
            "Count": str(rtv_count),
            "AvgActualTime": f"{rtv_actual:.6f}",
            "AvgDelayTime": f"{rtv_delay:.6f}",
            "AvgWaitTime": f"{rtv_wait:.6f}",
            "AvgIdleTime": f"{rtv_idle:.6f}",
            "TotalInbound": str(rtv_inbound),
            "TotalOutbound": str(rtv_outbound)
        }
        
        # SRM
        srm_actual = base_actual_time * np.random.uniform(1.5, 3.0)
        srm_delay = base_delay_time * np.random.uniform(0.8, 2.5)
        srm_wait = 0 if np.random.random() > 0.3 else base_wait_time * 0.5  # 70% í™•ë¥ ë¡œ ëŒ€ê¸°ì—†ìŒ
        srm_idle = base_idle_time * np.random.uniform(0.5, 3.0)
        srm_inbound = int(actual_throughput * 0.25 * np.random.uniform(0.8, 1.2))  # 25% ë‹´ë‹¹
        srm_outbound = int(srm_inbound * np.random.uniform(0.0, 0.4))  # ë‚®ì€ ì™„ë£Œìœ¨
        
        equipment_performance["srm"] = {
            "Count": str(srm_count),
            "AvgActualTime": f"{srm_actual:.6f}",
            "AvgDelayTime": f"{srm_delay:.6f}",
            "AvgWaitTime": f"{srm_wait:.6f}",
            "AvgIdleTime": f"{srm_idle:.6f}",
            "TotalInbound": str(srm_inbound),
            "TotalOutbound": str(srm_outbound)
        }
        
        # Robot Arm
        robot_actual = base_actual_time * np.random.uniform(0.2, 2.0)  # ë¹ ë¥¸ ì‘ì—…
        robot_delay = 0 if np.random.random() > 0.2 else base_delay_time * 0.5  # 80% í™•ë¥ ë¡œ ì§€ì—°ì—†ìŒ
        robot_wait = base_wait_time * np.random.uniform(0.2, 2.0)
        robot_idle = base_idle_time * np.random.uniform(0.2, 3.0)
        robot_inbound = int(actual_throughput * 0.15 * np.random.uniform(0.8, 1.2))  # 15% ë‹´ë‹¹
        robot_outbound = int(robot_inbound * np.random.uniform(0.0, 0.2))  # ë§¤ìš° ë‚®ì€ ì™„ë£Œìœ¨
        
        equipment_performance["robotArm"] = {
            "Count": str(robot_arm_count),
            "AvgActualTime": f"{robot_actual:.6f}",
            "AvgDelayTime": f"{robot_delay:.6f}",
            "AvgWaitTime": f"{robot_wait:.6f}",
            "AvgIdleTime": f"{robot_idle:.6f}",
            "TotalInbound": str(robot_inbound),
            "TotalOutbound": str(robot_outbound)
        }
        
        # ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ êµ¬ì„±
        scenario = {
            "scenario_id": scenario_id,
            "metadata": {
                "warehouse_type": warehouse["description"],
                "equipment_config": equipment["name"],
                "operation_scenario": operation["name"],
                "equipment_condition": condition["name"],
                "variation_id": variation,
                "automation_level": equipment["automation_level"],
                "simulation_date": datetime.now().isoformat()
            },
            "query": {
                **equipment_performance,
                "rack": {
                    "Count": str(rack_count)
                },
                "randingArea": {
                    "Area": str(warehouse["area"])
                }
            }
        }
        
        return scenario
    
    def save_scenarios_for_unreal_simulation(self, scenarios: List[Dict], 
                                           output_file: str = "simulation_scenarios.json") -> None:
        """
        ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ìš© ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ ì €ì¥
        """
        # ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°°ì¹˜ë³„ë¡œ ë¶„í•  (ì–¸ë¦¬ì–¼ì—ì„œ ì²˜ë¦¬í•˜ê¸° ì‰½ê²Œ)
        batch_size = 100
        batches = [scenarios[i:i + batch_size] for i in range(0, len(scenarios), batch_size)]
        
        simulation_config = {
            "total_scenarios": len(scenarios),
            "batch_count": len(batches),
            "batch_size": batch_size,
            "generation_timestamp": datetime.now().isoformat(),
            "parameters_used": self.scenario_parameters,
            "batches": []
        }
        
        for i, batch in enumerate(batches):
            batch_info = {
                "batch_id": i + 1,
                "scenario_count": len(batch),
                "scenarios": batch
            }
            simulation_config["batches"].append(batch_info)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(simulation_config, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        print(f"   â€¢ ì´ {len(scenarios):,}ê°œ ì‹œë‚˜ë¦¬ì˜¤")
        print(f"   â€¢ {len(batches)}ê°œ ë°°ì¹˜ë¡œ ë¶„í• ")
        print(f"   â€¢ ê° ë°°ì¹˜ë‹¹ ìµœëŒ€ {batch_size}ê°œ ì‹œë‚˜ë¦¬ì˜¤")
    
    def create_training_dataset_structure(self, scenarios: List[Dict]) -> pd.DataFrame:
        """
        ì‹œë‚˜ë¦¬ì˜¤ë¥¼ XGB í›ˆë ¨ìš© ë°ì´í„°ì…‹ êµ¬ì¡°ë¡œ ë³€í™˜ (ì‹œë®¬ë ˆì´ì…˜ ì „ - X-Labelë§Œ ìƒì„±)
        """
        try:
            from digital_twin_roi_model import DigitalTwinROIPredictor
            predictor = DigitalTwinROIPredictor()
        except ImportError:
            print("âš ï¸  digital_twin_roi_model ëª¨ë“ˆì´ ì—†ì–´ì„œ Mock í”¼ì²˜ ìƒì„±ê¸° ì‚¬ìš©")
            predictor = None
        
        dataset_rows = []
        
        print("ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ì „ í”¼ì²˜ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        for i, scenario in enumerate(scenarios):
            if i % 1000 == 0:
                print(f"   ì§„í–‰ë¥ : {i:,}/{len(scenarios):,} ({i/len(scenarios)*100:.1f}%)")
            
            # Feature ì¶”ì¶œ (X-Label)
            if predictor:
                features = predictor.extract_features_from_digital_twin(scenario)
            else:
                # Mock í”¼ì²˜ ìƒì„± (ì‹¤ì œ digital_twin_roi_modelì´ ì—†ì„ ë•Œ)
                features = self._create_mock_features(scenario)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            row = {
                'scenario_id': scenario['scenario_id'],
                'warehouse_type': scenario['metadata']['warehouse_type'],
                'equipment_config': scenario['metadata']['equipment_config'],
                'operation_scenario': scenario['metadata']['operation_scenario'],
                'equipment_condition': scenario['metadata']['equipment_condition'],
                **features,  # 28ê°œ ê¸°ë³¸ X-Label
                # Y-Labelì€ ì‹œë®¬ë ˆì´ì…˜ í›„ì— ì¶”ê°€ë¨
                'kpi_score': None,      # ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
                'roi_actual': None,     # ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼  
                'eff_score': None       # ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
            }
            
            dataset_rows.append(row)
        
        df = pd.DataFrame(dataset_rows)
        print(f"âœ… ì‹œë®¬ë ˆì´ì…˜ ì „ í”¼ì²˜ì…‹ ìƒì„± ì™„ë£Œ: {df.shape}")
        
        return df
    
    def _create_mock_features(self, scenario: Dict) -> Dict[str, float]:
        """
        digital_twin_roi_modelì´ ì—†ì„ ë•Œ Mock í”¼ì²˜ ìƒì„±
        """
        query = scenario['query']
        
        # ê¸°ë³¸ 28ê°œ í”¼ì²˜ Mock ìƒì„±
        features = {}
        
        # ì¥ë¹„ ìˆ˜ëŸ‰ í”¼ì²˜
        for equipment in ['cnv', 'rtv', 'srm', 'robotArm']:
            if equipment in query:
                features[f'{equipment}_count'] = float(query[equipment]['Count'])
        
        features['rack_count'] = float(query['rack']['Count'])
        features['warehouse_area'] = float(query['randingArea']['Area'])
        
        # ì„±ëŠ¥ ì§€í‘œ í”¼ì²˜ë“¤ (ì‹œë®¬ë ˆì´ì…˜ ì „ ì¶”ì •ê°’)
        for equipment in ['cnv', 'rtv', 'srm', 'robotArm']:
            if equipment in query:
                features[f'{equipment}_avg_actual_time'] = float(query[equipment]['AvgActualTime'])
                features[f'{equipment}_avg_delay_time'] = float(query[equipment]['AvgDelayTime'])
                features[f'{equipment}_avg_wait_time'] = float(query[equipment]['AvgWaitTime'])
                features[f'{equipment}_avg_idle_time'] = float(query[equipment]['AvgIdleTime'])
                features[f'{equipment}_total_inbound'] = float(query[equipment]['TotalInbound'])
                features[f'{equipment}_total_outbound'] = float(query[equipment]['TotalOutbound'])
        
        # ì¶”ê°€ ê³„ì‚° í”¼ì²˜ë“¤
        total_inbound = sum(float(query[eq]['TotalInbound']) for eq in ['cnv', 'rtv', 'srm', 'robotArm'] if eq in query)
        total_outbound = sum(float(query[eq]['TotalOutbound']) for eq in ['cnv', 'rtv', 'srm', 'robotArm'] if eq in query)
        
        features['total_throughput'] = total_inbound
        features['completion_rate'] = total_outbound / total_inbound if total_inbound > 0 else 0
        features['equipment_density'] = features['rack_count'] / (features['warehouse_area'] / 1000000)  # per mÂ²
        
        return features

    def process_simulation_results(self, simulation_results: str, scenario_id: int) -> Dict[str, float]:
        """
        ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ Y-Label ì¶”ì¶œ
        
        Args:
            simulation_results: ì–¸ë¦¬ì–¼ì—ì„œ ë°›ì€ ê²°ê³¼ í…ìŠ¤íŠ¸
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            
        Returns:
            Dict: íŒŒì‹±ëœ KPI, ROI, EFF ê°’ë“¤
        """
        import re
        
        # ì •ê·œì‹ìœ¼ë¡œ í•µì‹¬ ì§€í‘œ ì¶”ì¶œ
        patterns = {
            'throughput': r'(\d+\.?\d*)\s*ì˜?\s*ì²˜ë¦¬ëŸ‰',
            'utilization': r'(\d+\.?\d*)%\s*ì˜?\s*í™œìš©ë„',
            'cost': r'ë¹„ìš©\s*(\d+\.?\d*)\s*ë‹¬ëŸ¬',
            'profit': r'(\d+\.?\d*)\s*ì˜?\s*ì´ìµ',
            'efficiency': r'íš¨ìœ¨ì„±\s*ì ìˆ˜ëŠ”\s*(\d+\.?\d*)%'
        }
        
        parsed_data = {}
        
        for key, pattern in patterns.items():
            match = re.search(pattern, simulation_results)
            if match:
                parsed_data[key] = float(match.group(1))
            else:
                parsed_data[key] = 0.0
        
        # Y-Label ê³„ì‚°
        result = {
            'kpi_score': self._calculate_kpi_score(
                parsed_data.get('throughput', 0),
                parsed_data.get('utilization', 0)
            ),
            'roi_actual': self._calculate_roi_actual(
                parsed_data.get('profit', 0),
                parsed_data.get('cost', 1)
            ),
            'eff_score': parsed_data.get('efficiency', 0)
        }
        
        print(f"ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ {scenario_id} ê²°ê³¼ íŒŒì‹± ì™„ë£Œ: {result}")
        return result
    
    def _calculate_kpi_score(self, throughput: float, utilization: float) -> float:
        """
        KPI ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì²˜ë¦¬ëŸ‰ê³¼ í™œìš©ë„ë¥¼ ê²°í•©)
        """
        # ê°€ì¤‘ í‰ê· : ì²˜ë¦¬ëŸ‰ 60%, í™œìš©ë„ 40%
        kpi_score = (throughput * 0.6) + (utilization * 0.4)
        return round(kpi_score, 2)
    
    def _calculate_roi_actual(self, profit: float, cost: float) -> float:
        """
        ì‹¤ì œ ROI ê³„ì‚° (ì´ìµ/ë¹„ìš© * 100)
        """
        if cost == 0:
            return 0.0
        roi = (profit / cost) * 100
        return round(roi, 2)

    def integrate_analytics_features(self, base_features_df: pd.DataFrame, 
                                   analytics_data: Dict[int, Dict]) -> pd.DataFrame:
        """
        AnalyticsUtilì—ì„œ ì¶”ì¶œí•œ í”¼ì²˜ë“¤ì„ ê¸°ë³¸ í”¼ì²˜ì…‹ì— í†µí•©
        
        Args:
            base_features_df: ê¸°ë³¸ 28ê°œ í”¼ì²˜ ë°ì´í„°í”„ë ˆì„
            analytics_data: AnalyticsUtilì—ì„œ ê³„ì‚°ëœ ë°ì´í„°
            
        Returns:
            í†µí•©ëœ í”¼ì²˜ ë°ì´í„°í”„ë ˆì„
        """
        print("ğŸ”— AnalyticsUtil í”¼ì²˜ í†µí•© ì¤‘...")
        
        enhanced_df = base_features_df.copy()
        
        # AnalyticsUtil í”¼ì²˜ ì¶”ê°€
        for idx, row in enhanced_df.iterrows():
            scenario_id = row['scenario_id']
            
            # analytics_dataì—ì„œ í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ì°¾ê¸°
            if scenario_id in analytics_data:
                data = analytics_data[scenario_id]
                
                # KPI í”¼ì²˜ ì¶”ê°€ (7ê°œ)
                if 'kpis' in data:
                    enhanced_df.at[idx, 'analytics_throughput'] = data['kpis'].get('throughput', 0)
                    enhanced_df.at[idx, 'analytics_waiting_time'] = data['kpis'].get('waiting_time', 0)
                    enhanced_df.at[idx, 'analytics_lead_time'] = data['kpis'].get('lead_time', 0)
                    enhanced_df.at[idx, 'analytics_resource_utilization'] = data['kpis'].get('resource_utilization', 0)
                    enhanced_df.at[idx, 'analytics_hourly_output'] = data['kpis'].get('hourly_output', 0)
                    enhanced_df.at[idx, 'analytics_bss'] = data['kpis'].get('bss', 0)
                    enhanced_df.at[idx, 'analytics_bps'] = data['kpis'].get('bps', 0)
                
                # Efficiency í”¼ì²˜ ì¶”ê°€ (6ê°œ)
                if 'efficiencys' in data:
                    enhanced_df.at[idx, 'analytics_production_line_output_rate'] = data['efficiencys'].get('Production_line_output_rate', 0)
                    enhanced_df.at[idx, 'analytics_source_efficiency'] = data['efficiencys'].get('Source_efficiency', 0)
                    enhanced_df.at[idx, 'analytics_workstation_efficiency'] = data['efficiencys'].get('Workstation_efficiency', 0)
                    enhanced_df.at[idx, 'analytics_production_line_efficiency'] = data['efficiencys'].get('Production_line_efficiency', 0)
                    enhanced_df.at[idx, 'analytics_total_store_rate'] = data['efficiencys'].get('total_store_rate', 0)
                    enhanced_df.at[idx, 'analytics_energy'] = data['efficiencys'].get('energy', 0)
                
                # ê¸°íƒ€ í”¼ì²˜ ì¶”ê°€ (2ê°œ)
                enhanced_df.at[idx, 'analytics_area_usage_rate'] = data.get('area_usage_rates', 0)
                enhanced_df.at[idx, 'analytics_logistic_traffic'] = data.get('logistic_traffic', 0)
        
        print(f"âœ… í”¼ì²˜ í†µí•© ì™„ë£Œ: {base_features_df.shape[1]}ê°œ â†’ {enhanced_df.shape[1]}ê°œ í”¼ì²˜")
        return enhanced_df

    def create_complete_training_dataset(self, scenarios: List[Dict], 
                                       simulation_results: Dict[int, str],
                                       analytics_data: Dict[int, Dict]) -> pd.DataFrame:
        """
        ì‹œë®¬ë ˆì´ì…˜ ì „/í›„ ë°ì´í„°ë¥¼ ëª¨ë‘ ê²°í•©í•œ ì™„ì „í•œ í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±
        
        Args:
            scenarios: ì‹œë®¬ë ˆì´ì…˜ ì „ ì‹œë‚˜ë¦¬ì˜¤ë“¤
            simulation_results: ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë“¤ (scenario_id: result_text)
            analytics_data: AnalyticsUtil ê³„ì‚° ê²°ê³¼ë“¤ (scenario_id: analytics_dict)
            
        Returns:
            ì™„ì „í•œ í›ˆë ¨ ë°ì´í„°ì…‹
        """
        print("ğŸ¯ ì™„ì „í•œ XGB í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # 1ë‹¨ê³„: ê¸°ë³¸ í”¼ì²˜ ìƒì„±
        base_df = self.create_training_dataset_structure(scenarios)
        
        # 2ë‹¨ê³„: AnalyticsUtil í”¼ì²˜ í†µí•©
        enhanced_df = self.integrate_analytics_features(base_df, analytics_data)
        
        # 3ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ Y-Label ì¶”ê°€
        for idx, row in enhanced_df.iterrows():
            scenario_id = row['scenario_id']
            
            if scenario_id in simulation_results:
                # ì–¸ë¦¬ì–¼ ê²°ê³¼ íŒŒì‹±
                parsed_results = self.process_simulation_results(
                    simulation_results[scenario_id], scenario_id
                )
                
                # Y-Label ì—…ë°ì´íŠ¸
                enhanced_df.at[idx, 'kpi_score'] = parsed_results['kpi_score']
                enhanced_df.at[idx, 'roi_actual'] = parsed_results['roi_actual'] 
                enhanced_df.at[idx, 'eff_score'] = parsed_results['eff_score']
        
        # ê²°ì¸¡ì¹˜ ì œê±° (ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤)
        complete_df = enhanced_df.dropna(subset=['kpi_score', 'roi_actual', 'eff_score'])
        
        print(f"ğŸ¯ ì™„ì „í•œ XGB ë°ì´í„°ì…‹ ì™„ì„±!")
        print(f"   â€¢ ì´ í”¼ì²˜ ìˆ˜: {complete_df.shape[1] - 8}ê°œ")  # ë©”íƒ€ë°ì´í„° 5ê°œ + Y-Label 3ê°œ ì œì™¸
        print(f"   â€¢ ê¸°ë³¸ í”¼ì²˜: 28ê°œ")
        print(f"   â€¢ AnalyticsUtil í”¼ì²˜: 15ê°œ") 
        print(f"   â€¢ Y-Label: 3ê°œ (KPI, ROI, EFF)")
        print(f"   â€¢ í›ˆë ¨ ìƒ˜í”Œ: {complete_df.shape[0]:,}ê°œ")
        
        return complete_df
    
    def generate_raw_data_csv(self, num_samples: int = 2000, output_file: str = "warehouse_raw_data.csv") -> pd.DataFrame:
        """
        ì‹œë®¬ë ˆì´ì…˜ ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¡œìš°ë°ì´í„° CSV ìƒì„±
        warehouse_data_2.csvì™€ ìœ ì‚¬í•œ í˜•íƒœì´ì§€ë§Œ ë””ì§€í„¸ íŠ¸ìœˆ ê´€ì  ë°˜ì˜
        
        Args:
            num_samples: ìƒì„±í•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜
            output_file: ì €ì¥í•  CSV íŒŒì¼ëª…
            
        Returns:
            ìƒì„±ëœ DataFrame
        """
        import numpy as np
        from datetime import datetime
        
        print(f"ğŸ­ ë””ì§€í„¸ íŠ¸ìœˆ ë¡œìš°ë°ì´í„° ìƒì„± ì¤‘... ({num_samples:,}ê°œ ìƒ˜í”Œ)")
        
        raw_data = []
        
        for i in range(num_samples):
            if i % 500 == 0:
                print(f"   ì§„í–‰ë¥ : {i:,}/{num_samples:,} ({i/num_samples*100:.1f}%)")
            
            # ê¸°ë³¸ ì°½ê³  íŠ¹ì„±
            warehouse_area = np.random.choice([50000000, 100000000, 150000000, 300000000])  # cmÂ²
            warehouse_size_m2 = warehouse_area / 10000  # mÂ²ë¡œ ë³€í™˜
            
            # ìš´ì˜ ê°•ë„ (ì‹œì¦Œ/í”¼í¬ ë“± ë°˜ì˜)
            season = np.random.choice([1, 2, 3, 4])  # 1:ë¹„ìˆ˜ê¸°, 2:í‰ì‹œ, 3:ì„±ìˆ˜ê¸°, 4:í”¼í¬
            operation_intensity = {1: 0.6, 2: 1.0, 3: 1.8, 4: 2.2}[season]
            
            # ì¥ë¹„ êµ¬ì„±
            automation_level = np.random.choice([2, 3, 4, 5])  # ê¸°ë³¸í˜•, í‘œì¤€í˜•, ê³ ê¸‰í˜•, ìµœê³ ê¸‰í˜•
            
            # ì¥ë¹„ë³„ ìˆ˜ëŸ‰ (ìë™í™” ë ˆë²¨ì— ë”°ë¼)
            equipment_ranges = {
                2: {"cnv": (5, 15), "rtv": (2, 8), "srm": (3, 12), "robot": (0, 2)},
                3: {"cnv": (10, 25), "rtv": (4, 12), "srm": (5, 15), "robot": (1, 3)},
                4: {"cnv": (15, 35), "rtv": (6, 18), "srm": (8, 20), "robot": (1, 4)},
                5: {"cnv": (20, 50), "rtv": (10, 25), "srm": (10, 30), "robot": (2, 6)}
            }
            
            ranges = equipment_ranges[automation_level]
            cnv_count = np.random.randint(ranges["cnv"][0], ranges["cnv"][1] + 1)
            rtv_count = np.random.randint(ranges["rtv"][0], ranges["rtv"][1] + 1)
            srm_count = np.random.randint(ranges["srm"][0], ranges["srm"][1] + 1)
            robot_count = np.random.randint(ranges["robot"][0], ranges["robot"][1] + 1)
            
            # ë™ ìˆ˜ëŸ‰
            rack_count = max(10, int(warehouse_area / 5000000))
            
            # ê¸°ë³¸ ì²˜ë¦¬ëŸ‰
            base_throughput = warehouse_size_m2 * np.random.uniform(0.8, 1.2)
            daily_throughput = base_throughput * operation_intensity
            
            # ì¥ë¹„ ìƒíƒœ (ë…¸í›„ë„ ë°˜ì˜)
            equipment_age = np.random.randint(1, 20)  # ë…„
            condition_factor = max(0.6, 1.0 - (equipment_age * 0.02))  # ë‚˜ì´ì— ë”°ë¥¸ ì„±ëŠ¥ ì €í•˜
            
            # ì‹¤ì œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            noise_factor = np.random.normal(1.0, 0.1)  # Â±10% ë…¸ì´ì¦ˆ
            
            # ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
            base_time = 5 + (equipment_age * 0.3)
            processing_time = base_time * (2.0 - condition_factor) * noise_factor / operation_intensity
            processing_time = max(5.0, min(processing_time, 6500.0))  # í˜„ì‹¤ì  ë²”ìœ„
            
            # ì •í™•ë„ (%)
            base_accuracy = 95.0
            accuracy_penalty = (equipment_age * 0.5) + (1.0 - condition_factor) * 10
            picking_accuracy = base_accuracy - accuracy_penalty + (automation_level - 2) * 2
            picking_accuracy = max(72.0, min(picking_accuracy, 98.0))
            
            # ì˜¤ë¥˜ìœ¨ (%)
            base_error = 1.0
            error_increase = (equipment_age * 0.1) + (1.0 - condition_factor) * 3
            error_rate = base_error + error_increase - (automation_level - 2) * 0.3
            error_rate = max(0.5, min(error_rate, 8.0))
            
            # ë¹„ìš© (ì›í™” ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½)
            labor_base = 50000  # ê¸°ë³¸ ì¸ê±´ë¹„
            equipment_overhead = (cnv_count * 1000 + rtv_count * 2000 + srm_count * 3000 + robot_count * 5000)
            labor_cost = labor_base + equipment_overhead * (2.0 - condition_factor)
            labor_cost = max(35000, min(labor_cost, 80000))
            
            # ë¶€ê°€ íŠ¹ì„±ë“¤
            workers = max(5, int((cnv_count + rtv_count + srm_count) * 0.8))
            shift_type = np.random.choice([1, 2, 3])  # 1êµëŒ€, 2êµëŒ€, 3êµëŒ€
            day_of_week = np.random.choice([1, 2, 3, 4, 5, 6, 7])
            
            # WMS/AGV êµ¬í˜„ ì—¬ë¶€ (ìë™í™” ë ˆë²¨ê³¼ ìƒê´€ê´€ê³„)
            wms_prob = min(0.9, automation_level * 0.2)
            agv_prob = min(0.8, (automation_level - 1) * 0.25)
            wms_implemented = 1 if np.random.random() < wms_prob else 0
            agv_implemented = 1 if np.random.random() < agv_prob else 0
            
            # ë¡œìš°ë°ì´í„° ìƒ˜í”Œ ìƒì„±
            sample = {
                # ì°½ê³  ê¸°ë³¸ íŠ¹ì„±
                'warehouse_area_m2': int(warehouse_size_m2),
                'daily_throughput': int(daily_throughput),
                'total_equipment_count': cnv_count + rtv_count + srm_count + robot_count,
                'workers': workers,
                'shift_type': shift_type,
                
                # ìë™í™” ì„¤ë¹„
                'conveyor_count': cnv_count,
                'rtv_agv_count': rtv_count, 
                'srm_count': srm_count,
                'robot_arm_count': robot_count,
                'rack_count': rack_count,
                
                # ì‹œìŠ¤í…œ êµ¬í˜„
                'wms_implemented': wms_implemented,
                'agv_implemented': agv_implemented,
                'automation_level': automation_level,
                
                # ìš´ì˜ ì¡°ê±´
                'season': season,
                'day_of_week': day_of_week,
                'equipment_age_years': equipment_age,
                'condition_factor': round(condition_factor, 3),
                
                # ì¥ë¹„ ì„±ëŠ¥ ì§€í‘œ (í•µì‹¬)
                'conveyor_utilization': round(np.random.uniform(0.3, 0.8), 3),
                'rtv_utilization': round(np.random.uniform(0.4, 0.7), 3),
                'srm_utilization': round(np.random.uniform(0.5, 0.9), 3),
                'robot_utilization': round(np.random.uniform(0.2, 0.6), 3),
                
                # ì‹œê°„ ì§€í‘œ
                'avg_conveyor_time': round(np.random.uniform(3.0, 8.0), 2),
                'avg_rtv_time': round(np.random.uniform(6.0, 12.0), 2),
                'avg_srm_time': round(np.random.uniform(4.0, 10.0), 2),
                'avg_robot_time': round(np.random.uniform(1.0, 5.0), 2),
                
                # í’ˆì§ˆ ì§€í‘œ
                'equipment_efficiency': round(condition_factor * 100, 1),
                'maintenance_frequency': round(equipment_age * 0.5, 1),
                
                # === Y-Label (íƒ€ê²Ÿ ë³€ìˆ˜) ===
                'processing_time_seconds': round(processing_time, 2),
                'picking_accuracy_percent': round(picking_accuracy, 2),
                'error_rate_percent': round(error_rate, 2),
                'labor_cost_per_order_krw': int(labor_cost)
            }
            
            raw_data.append(sample)
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(raw_data)
        
        # CSV ì €ì¥
        df.to_csv(output_file, index=False)
        
        print(f"âœ… ë¡œìš°ë°ì´í„° CSV ìƒì„± ì™„ë£Œ!")
        print(f"   ğŸ“„ íŒŒì¼: {output_file}")
        print(f"   ğŸ“Š í¬ê¸°: {df.shape[0]:,} rows Ã— {df.shape[1]} columns")
        print(f"   ğŸ¯ X-Label: {df.shape[1] - 4}ê°œ (ë§ˆì§€ë§‰ 4ê°œëŠ” Y-Label)")
        print(f"   ğŸ¯ Y-Label: processing_time, picking_accuracy, error_rate, labor_cost")
        
        # ë°ì´í„° í’ˆì§ˆ ì²´í¬
        print(f"\nğŸ“ˆ Y-Label ë¶„í¬:")
        print(f"   â€¢ ì²˜ë¦¬ì‹œê°„: {df['processing_time_seconds'].min():.1f}~{df['processing_time_seconds'].max():.1f}ì´ˆ")
        print(f"   â€¢ ì •í™•ë„: {df['picking_accuracy_percent'].min():.1f}~{df['picking_accuracy_percent'].max():.1f}%")
        print(f"   â€¢ ì˜¤ë¥˜ìœ¨: {df['error_rate_percent'].min():.1f}~{df['error_rate_percent'].max():.1f}%") 
        print(f"   â€¢ ë¹„ìš©: {df['labor_cost_per_order_krw'].min():,}~{df['labor_cost_per_order_krw'].max():,}ì›")
        
        return df

def main_bigdata_strategy():
    """
    ë¹…ë°ì´í„° êµ¬ì¶• ì „ëµ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜ ì „/í›„ í†µí•© ë°©ì‹)
    """
    generator = DigitalTwinBigDataGenerator()
    
    print("ğŸ—ï¸  ë””ì§€í„¸ íŠ¸ìœˆ ë¹…ë°ì´í„° êµ¬ì¶• ì „ëµ v2.0")
    print("=" * 60)
    print("ğŸ“Œ ì‹œë®¬ë ˆì´ì…˜ ì „/í›„ ë°ì´í„° í†µí•©í˜• XGB í›ˆë ¨ì…‹ êµ¬ì¶•")
    
    # Step 1: ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    print("\nğŸ“‹ 1ë‹¨ê³„: ì²´ê³„ì  ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±")
    scenarios = generator.generate_simulation_scenarios(num_scenarios_per_combination=5)  # ë°ëª¨ìš© 5ê°œ
    
    # Step 2: ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ìš© íŒŒì¼ ì €ì¥
    print("\nğŸ’¾ 2ë‹¨ê³„: ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • íŒŒì¼ ìƒì„±")
    generator.save_scenarios_for_unreal_simulation(scenarios[:20])  # ë°ëª¨ìš© 20ê°œë§Œ
    
    # Step 3: ì‹œë®¬ë ˆì´ì…˜ ì „ í”¼ì²˜ì…‹ ìƒì„±
    print("\nğŸ”§ 3ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ì „ í”¼ì²˜ì…‹ ìƒì„±")
    pre_simulation_df = generator.create_training_dataset_structure(scenarios[:20])
    
    # Step 4: Mock ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„± (ì‹¤ì œë¡œëŠ” ì–¸ë¦¬ì–¼ì—ì„œ ë°›ì•„ì˜´)
    print("\nğŸ­ 4ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°ëª¨ ìƒì„±")
    mock_simulation_results = {}
    mock_analytics_data = {}
    
    for i in range(1, 21):  # 20ê°œ ì‹œë‚˜ë¦¬ì˜¤
        # ì–¸ë¦¬ì–¼ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
        throughput = np.random.uniform(5.0, 15.0)
        utilization = np.random.uniform(80.0, 98.0)
        cost = np.random.uniform(3000.0, 8000.0)
        profit = np.random.uniform(10.0, 50.0)
        efficiency = np.random.uniform(85.0, 97.0)
        
        mock_simulation_results[i] = f"""KPI: ì„±ê³¼ëŠ” {throughput:.1f}ì˜ ì²˜ë¦¬ëŸ‰ê³¼ {utilization:.1f}%ì˜ í™œìš©ë„ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
ROI: ë¹„ìš© {cost:.2f} ë‹¬ëŸ¬ì— ëŒ€í•´ {profit:.1f}ì˜ ì´ìµì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
EFF: íš¨ìœ¨ì„± ì ìˆ˜ëŠ” {efficiency:.1f}%ì…ë‹ˆë‹¤.

ëŒ€ê¸° ì‹œê°„ê³¼ ì§€ì—° ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´ ë¡œë´‡ì˜ ì‘ì—… ìŠ¤ì¼€ì¤„ì„ ìµœì í™”í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."""
        
        # AnalyticsUtil ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
        mock_analytics_data[i] = {
            'kpis': {
                'throughput': np.random.uniform(1, 10),
                'waiting_time': np.random.uniform(1, 10), 
                'lead_time': np.random.uniform(1, 10),
                'resource_utilization': np.random.uniform(1, 10),
                'hourly_output': np.random.uniform(1, 10),
                'bss': np.random.uniform(1, 10),
                'bps': np.random.uniform(1, 10)
            },
            'efficiencys': {
                'Production_line_output_rate': np.random.uniform(1, 10),
                'Source_efficiency': np.random.uniform(1, 10),
                'Workstation_efficiency': np.random.uniform(1, 10), 
                'Production_line_efficiency': np.random.uniform(1, 10),
                'total_store_rate': np.random.uniform(1, 10),
                'energy': np.random.uniform(1, 10)
            },
            'area_usage_rates': np.random.uniform(50.0, 95.0),
            'logistic_traffic': np.random.randint(100, 1000)
        }
    
    # Step 5: ì™„ì „í•œ í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±
    print("\nğŸ¯ 5ë‹¨ê³„: ì™„ì „í•œ XGB í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±")
    complete_df = generator.create_complete_training_dataset(
        scenarios[:20], 
        mock_simulation_results,
        mock_analytics_data
    )
    
    # Step 6: XGBoost ë‹¤ì¤‘ íšŒê·€ ê°€ëŠ¥ì„± í™•ì¸
    print(f"\nğŸ¤– 6ë‹¨ê³„: XGBoost MultiOutput Regressor ì¤€ë¹„ì„± ì²´í¬")
    
    # í”¼ì²˜ ì»¬ëŸ¼ê³¼ íƒ€ê²Ÿ ì»¬ëŸ¼ ë¶„ë¦¬
    feature_cols = [col for col in complete_df.columns 
                   if col not in ['scenario_id', 'warehouse_type', 'equipment_config', 
                                 'operation_scenario', 'equipment_condition', 
                                 'kpi_score', 'roi_actual', 'eff_score']]
    
    target_cols = ['kpi_score', 'roi_actual', 'eff_score']
    
    print(f"   âœ… X-Label (í”¼ì²˜): {len(feature_cols)}ê°œ")
    print(f"      â€¢ ê¸°ë³¸ í”¼ì²˜: 28ê°œ")
    print(f"      â€¢ AnalyticsUtil í”¼ì²˜: 15ê°œ")
    print(f"   âœ… Y-Label (íƒ€ê²Ÿ): {len(target_cols)}ê°œ")
    print(f"      â€¢ KPI Score: ì²˜ë¦¬ëŸ‰ + í™œìš©ë„ ì¢…í•©")
    print(f"      â€¢ ROI Actual: ì‹¤ì œ íˆ¬ììˆ˜ìµë¥ ")
    print(f"      â€¢ EFF Score: íš¨ìœ¨ì„± ì ìˆ˜")
    print(f"   âœ… í›ˆë ¨ ìƒ˜í”Œ: {complete_df.shape[0]}ê°œ")
    
    # ë°ì´í„° í’ˆì§ˆ ì²´í¬
    print(f"\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ì²´í¬:")
    print(f"   â€¢ ê²°ì¸¡ì¹˜: {complete_df.isnull().sum().sum()}ê°œ")
    print(f"   â€¢ Y-Label ë²”ìœ„:")
    for col in target_cols:
        print(f"     - {col}: {complete_df[col].min():.2f} ~ {complete_df[col].max():.2f}")
    
    print(f"\nğŸ’¡ ì‹¤ì œ êµ¬í˜„ ë¡œë“œë§µ:")
    total_scenarios = len(scenarios)
    print(f"   1ï¸âƒ£ ì–¸ë¦¬ì–¼ ì‹œë®¬ë ˆì´ì…˜: {total_scenarios:,}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰")
    print(f"   2ï¸âƒ£ AnalyticsUtil ì—°ë™: ì¶”ê°€ í”¼ì²˜ 15ê°œ ì¶”ì¶œ")
    print(f"   3ï¸âƒ£ XGB MultiOutputRegressor í›ˆë ¨:")
    print(f"      from sklearn.multioutput import MultiOutputRegressor")
    print(f"      from xgboost import XGBRegressor")
    print(f"      model = MultiOutputRegressor(XGBRegressor())")
    print(f"   4ï¸âƒ£ 3ê°œ íƒ€ê²Ÿ ë™ì‹œ ì˜ˆì¸¡: KPI, ROI, EFF")
    
    return scenarios, complete_df

def demo_xgb_multioutput_training(complete_df: pd.DataFrame) -> None:
    """
    XGBoost MultiOutput Regressor ë°ëª¨ í›ˆë ¨
    """
    print("\nğŸš€ XGBoost MultiOutput Regressor ë°ëª¨ í›ˆë ¨")
    print("=" * 50)
    
    try:
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import mean_squared_error, r2_score
        import xgboost as xgb
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = [col for col in complete_df.columns 
                       if col not in ['scenario_id', 'warehouse_type', 'equipment_config', 
                                     'operation_scenario', 'equipment_condition', 
                                     'kpi_score', 'roi_actual', 'eff_score']]
        
        X = complete_df[feature_cols].fillna(0)  # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        y = complete_df[['kpi_score', 'roi_actual', 'eff_score']]
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # MultiOutput XGBoost ëª¨ë¸
        model = MultiOutputRegressor(
            xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
        )
        
        # í›ˆë ¨
        print("ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        
        # í‰ê°€
        print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€:")
        target_names = ['KPI Score', 'ROI Actual', 'EFF Score']
        
        for i, target_name in enumerate(target_names):
            mse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i])
            r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])
            print(f"   â€¢ {target_name}:")
            print(f"     - MSE: {mse:.4f}")
            print(f"     - RÂ²: {r2:.4f}")
        
        print("\nâœ… XGBoost MultiOutput íšŒê·€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        
    except ImportError as e:
        print(f"âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ: {e}")
        print("   ì„¤ì¹˜ ëª…ë ¹: pip install scikit-learn xgboost")
    except Exception as e:
        print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def generate_raw_data_only(num_samples: int = 2000):
    """
    ë¡œìš°ë°ì´í„° CSVë§Œ ìƒì„±í•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜
    """
    generator = DigitalTwinBigDataGenerator()
    
    print("ğŸ­ ë””ì§€í„¸ íŠ¸ìœˆ ê¸°ë°˜ ë¡œìš°ë°ì´í„° ìƒì„± ëª¨ë“œ")
    print("=" * 50)
    
    # ë¡œìš°ë°ì´í„° CSV ìƒì„±
    raw_df = generator.generate_raw_data_csv(num_samples, "warehouse_raw_data.csv")
    
    print(f"\nğŸ¯ ìƒì„± ì™„ë£Œ! XGBoost í›ˆë ¨ ì¦‰ì‹œ ê°€ëŠ¥")
    print(f"   ğŸ“„ íŒŒì¼: warehouse_raw_data.csv") 
    print(f"   ğŸ” ì‚¬ìš©ë²•: pd.read_csv('warehouse_raw_data.csv')")
    
    return raw_df

if __name__ == "__main__":
    import sys
    
    # ì‹¤í–‰ ëª¨ë“œ ì„ íƒ
    if len(sys.argv) > 1 and sys.argv[1] == "--raw-only":
        # ë¡œìš°ë°ì´í„°ë§Œ ìƒì„±
        num_samples = int(sys.argv[2]) if len(sys.argv) > 2 else 2000
        raw_df = generate_raw_data_only(num_samples)
    else:
        # ê¸°ë³¸ ëª¨ë“œ: ì‹œë®¬ë ˆì´ì…˜ í†µí•© ë°ì´í„°ì…‹
        scenarios, complete_df = main_bigdata_strategy()
        
        # XGBoost ë°ëª¨ ì‹¤í–‰
        if complete_df.shape[0] > 0:
            demo_xgb_multioutput_training(complete_df)