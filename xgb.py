import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# data.pyì—ì„œ ë°ì´í„° ìƒì„± í•¨ìˆ˜ë“¤ import
from data import generate_warehouse_raw_data, get_feature_target_columns, save_warehouse_data

# ì‹œë“œ ì„¤ì • (ì¬í˜„ì„±ì„ ìœ„í•´)  
np.random.seed(42)

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€: XGBoost MultiOutput ëª¨ë¸ í›ˆë ¨ ë° ë¶„ì„
# =============================================================================

# ë°ì´í„° ìƒì„± (data.pyì—ì„œ í•¨ìˆ˜ í˜¸ì¶œ)
print("ğŸ­ data.pyì—ì„œ ì°½ê³  ë°ì´í„° ìƒì„± ì¤‘...")
df = generate_warehouse_raw_data(2000)

# ë°ì´í„° í™•ì¸
print("ğŸ­ warehouse_raw_data.csv í˜•íƒœì˜ ê°€ìƒ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
print("=" * 60)
print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape}")

# ì£¼ìš” í†µê³„
print(f"\n=== ê¸°ë³¸ í†µê³„ ===")
print(f"ì°½ê³  ë©´ì  í‰ê· : {df['warehouse_area_m2'].mean():.0f}mÂ² (ë²”ìœ„: {df['warehouse_area_m2'].min():.0f}-{df['warehouse_area_m2'].max():.0f})")
print(f"ì¼ì¼ ì²˜ë¦¬ëŸ‰ í‰ê· : {df['daily_throughput'].mean():.0f}ê±´ (ë²”ìœ„: {df['daily_throughput'].min()}-{df['daily_throughput'].max()})")
print(f"ì´ ì¥ë¹„ ìˆ˜ í‰ê· : {df['total_equipment_count'].mean():.0f}ëŒ€ (ë²”ìœ„: {df['total_equipment_count'].min()}-{df['total_equipment_count'].max()})")
print(f"ì‘ì—…ì ìˆ˜ í‰ê· : {df['workers'].mean():.0f}ëª… (ë²”ìœ„: {df['workers'].min()}-{df['workers'].max()})")
print(f"ìë™í™” ìˆ˜ì¤€ í‰ê· : {df['automation_level'].mean():.1f} (ë²”ìœ„: {df['automation_level'].min()}-{df['automation_level'].max()})")

print(f"\n=== Y-Label ë¶„í¬ ===")
print(f"ì²˜ë¦¬ì‹œê°„: {df['processing_time_seconds'].min():.1f}~{df['processing_time_seconds'].max():.1f}ì´ˆ")
print(f"í”¼í‚¹ ì •í™•ë„: {df['picking_accuracy_percent'].min():.1f}~{df['picking_accuracy_percent'].max():.1f}%")
print(f"ì˜¤ë¥˜ìœ¨: {df['error_rate_percent'].min():.1f}~{df['error_rate_percent'].max():.1f}%")
print(f"ì£¼ë¬¸ë‹¹ ë¹„ìš©: {df['labor_cost_per_order_krw'].min():,}~{df['labor_cost_per_order_krw'].max():,}ì›")

print(f"\n=== ê¸°ìˆ  ë„ì… í˜„í™© ===")
print(f"WMS ë„ì…ë¥ : {df['wms_implemented'].mean():.1%}")
print(f"AGV ë„ì…ë¥ : {df['agv_implemented'].mean():.1%}")
print(f"WMS+AGV ë™ì‹œ ë„ì…ë¥ : {((df['wms_implemented']==1) & (df['agv_implemented']==1)).mean():.1%}")

print(f"\n=== ì¥ë¹„ êµ¬ì„± ===")
print(f"ì»¨ë² ì´ì–´ í‰ê· : {df['conveyor_count'].mean():.1f}ëŒ€")
print(f"RTV/AGV í‰ê· : {df['rtv_agv_count'].mean():.1f}ëŒ€") 
print(f"SRM í‰ê· : {df['srm_count'].mean():.1f}ëŒ€")
print(f"ë¡œë´‡ì•” í‰ê· : {df['robot_arm_count'].mean():.1f}ëŒ€")
print(f"ë™ ìˆ˜ í‰ê· : {df['rack_count'].mean():.1f}ê°œ")

# XGBoost MultiOutput ëª¨ë¸ í›ˆë ¨
print("\nğŸ¤– XGBoost MultiOutput íšŒê·€ ëª¨ë¸ í›ˆë ¨")
print("=" * 50)

# X-Labelê³¼ Y-Label ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (data.pyì—ì„œ)
feature_columns, target_columns = get_feature_target_columns()

X = df[feature_columns]
y = df[target_columns]

print(f"ğŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_columns)}ê°œ")
print(f"ğŸ¯ íƒ€ê²Ÿ ìˆ˜: {len(target_columns)}ê°œ")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# MultiOutput XGBoost ëª¨ë¸
try:
    from sklearn.multioutput import MultiOutputRegressor
    
    model = MultiOutputRegressor(
        XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            verbosity=0
        )
    )
    
    print("ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€:")
    target_names = ['ì²˜ë¦¬ì‹œê°„(ì´ˆ)', 'ì •í™•ë„(%)', 'ì˜¤ë¥˜ìœ¨(%)', 'ë¹„ìš©(ì›)']
    
    for i, target_name in enumerate(target_names):
        mae = mean_absolute_error(y_test.iloc[:, i], y_pred[:, i])
        rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))
        r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])
        print(f"   â€¢ {target_name:12s}: MAE={mae:6.2f}, RMSE={rmse:6.2f}, RÂ²={r2:.3f}")

    print("\nâœ… MultiOutput íšŒê·€ í›ˆë ¨ ì™„ë£Œ!")
    
except ImportError:
    print("âŒ scikit-learnì˜ MultiOutputRegressorë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   ëŒ€ì‹  ë‹¨ì¼ íƒ€ê²Ÿ ëª¨ë¸ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.")
    
    # ë‹¨ì¼ íƒ€ê²Ÿ ëª¨ë¸ (processing_time_seconds)
    model = XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        verbosity=0
    )
    
    y_single = df['processing_time_seconds']
    X_train, X_test, y_train, y_test = train_test_split(X, y_single, test_size=0.2, random_state=42)
    
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}")
    print(f"RÂ²: {r2_score(y_test, y_pred):.3f}")

# íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (MultiOutputì˜ ê²½ìš° ì²« ë²ˆì§¸ íƒ€ê²Ÿ ê¸°ì¤€)
try:
    if hasattr(model, 'feature_importances_'):
        # ë‹¨ì¼ ëª¨ë¸ì¸ ê²½ìš°
        importances = model.feature_importances_
    else:
        # MultiOutput ëª¨ë¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ estimator ì‚¬ìš©
        importances = model.estimators_[0].feature_importances_
    
    feature_importance = pd.DataFrame({
        'feature': feature_columns,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    print(f"\nğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ Top 10:")
    for i, row in feature_importance.head(10).iterrows():
        print(f"   {row['feature']:25s}: {row['importance']:.3f}")
        
except Exception as e:
    print(f"íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

# ê¸°ìˆ  ë„ì… íš¨ê³¼ ë¶„ì„
print("\nğŸ’¡ WMS/AGV ë„ì… íš¨ê³¼ ë¶„ì„:")
print("=" * 40)

# WMS ë„ì… íš¨ê³¼
wms_effect = df.groupby('wms_implemented')[['processing_time_seconds', 'picking_accuracy_percent', 'error_rate_percent']].mean()
print("WMS ë„ì… íš¨ê³¼:")
print(wms_effect.round(2))

print()

# AGV ë„ì… íš¨ê³¼  
agv_effect = df.groupby('agv_implemented')[['processing_time_seconds', 'picking_accuracy_percent', 'error_rate_percent']].mean()
print("AGV ë„ì… íš¨ê³¼:")
print(agv_effect.round(2))

print()

# WMS+AGV ë™ì‹œ ë„ì… íš¨ê³¼
df['tech_combo'] = df['wms_implemented'].astype(str) + '_' + df['agv_implemented'].astype(str)
combo_labels = {'0_0': 'None', '1_0': 'WMSë§Œ', '0_1': 'AGVë§Œ', '1_1': 'WMS+AGV'}
df['tech_combo'] = df['tech_combo'].map(combo_labels)

combo_effect = df.groupby('tech_combo')[['processing_time_seconds', 'picking_accuracy_percent', 'error_rate_percent']].mean()
print("ê¸°ìˆ  ì¡°í•©ë³„ íš¨ê³¼:")
print(combo_effect.round(2))

# ë°ì´í„° ì €ì¥ (data.py í•¨ìˆ˜ ì‚¬ìš©)
output_file = 'warehouse_synthetic_data.csv'
df_save = df.drop('tech_combo', axis=1)  # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
save_warehouse_data(df_save, output_file)
print(f"\nğŸ’¾ ê°€ìƒ ì°½ê³  ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}")
print(f"   ğŸ“Š í¬ê¸°: {df_save.shape}")
print(f"   ğŸ¯ X-Label: {len(feature_columns)}ê°œ")
print(f"   ğŸ¯ Y-Label: {len(target_columns)}ê°œ")

print(f"\nâœ… ë°ì´í„° í’ˆì§ˆ ì²´í¬:")
print(f"   â€¢ ê²°ì¸¡ê°’: {df_save.isnull().sum().sum()}ê°œ")
print(f"   â€¢ ë°ì´í„° íƒ€ì…:")
for dtype, count in df_save.dtypes.value_counts().items():
    print(f"     - {dtype}: {count}ê°œ ì»¬ëŸ¼")

print(f"\nğŸ¯ ì‚¬ìš©ë²•:")
print(f"   import pandas as pd")
print(f"   df = pd.read_csv('{output_file}')")
print(f"   # ë°”ë¡œ XGBoost MultiOutput í›ˆë ¨ ê°€ëŠ¥!")